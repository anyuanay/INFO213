{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anyuanay/INFO213/blob/main/INFO213_Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Km0XQRaaAvP"
      },
      "source": [
        "## Drexel University\n",
        "## College of Computing and Informatics\n",
        "## INFO 213: Data Science Programming II\n",
        "## Assignment 1\n",
        "## Due Date: Sunday, April 13, 2025\n",
        "## This assignment counts for 15% of the final grade\n",
        "\n",
        "\n",
        "### A. What to Hand In\n",
        "\n",
        "Sumbit a completed this Jupyter notebook.\n",
        "\n",
        "### B. How to Hand In\n",
        "\n",
        "Submit your Jupyter notebook file through the course website in the Blackboard Learn system.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YOUR NAME:"
      ],
      "metadata": {
        "id": "gm_xyvquR-1r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRxdEw_NF1Db"
      },
      "outputs": [],
      "source": [
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JonBzpD19Dsp"
      },
      "source": [
        "# Question 1: Implement a single variable perceptron\n",
        "In this question, you are asked to implement the perceptron learning algorithm for input with a single variable, i.e., learn a linear function $z=w_0+w_1x$ to classify a single value $x$ as $1$ or $-1$.\n",
        "The perceptron algorithm can be summarized by the following steps:\n",
        "1. Initialize the weights $w_0$ and $w_1$.\n",
        "2. For each training example $x^{(i)}$,\n",
        " 1. Compute the linear combination: $z^{(i)}=w_0 + w_1{x}^{(i)}$\n",
        " 2. Compute the output value\n",
        " \\begin{equation}\n",
        "    \\bar{y}^{(i)}=\\phi(z^{(i)})=\n",
        "\\begin{cases}\n",
        "    1,& \\text{if } z^{(i)}\\geq 0\\\\\n",
        "    -1,              & \\text{otherwise}\n",
        "\\end{cases}\n",
        "\\end{equation}\n",
        " 3. Update the weights $w_0$ and $w_1$ as follows:\n",
        "    * $w_0 := w_0 + \\Delta w_0 = w_0 + \\eta(y^{(i)}-\\bar{y}^{(i)})$\n",
        "    * $w_1 := w_1 + \\Delta w_1 = w_1 + \\eta(y^{(i)}-\\bar{y}^{(i)})x^{(i)}$\n",
        "    * Where, $\\eta$ is a learning rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQA3VIfm_OfK"
      },
      "source": [
        "Step 1: In the following program, we have defined the functions `computeZ(x, w0, w1)`, `predict(x, w0, w1)`, `computeDelta(eta, x, ytrue, ypred)`, and `fit(eta, epochs, X, y, w0, w1, verbose=False)`. You need to complete the program by finishing the function `fit(eta, epochs, X, y, w0, w1, verboase=False)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ro4YmiLv9cCr"
      },
      "outputs": [],
      "source": [
        "## IMPLEMENT THE FOLLOWING FUNCTIONS\n",
        "\n",
        "def computeZ(x, w0, w1):\n",
        "    \"\"\"\n",
        "    compute the output z value given an input and the weights\n",
        "    input: x: the value of the input variable\n",
        "           w0: the weight of the bias\n",
        "           w1: the weight of the variable\n",
        "    output: the value of linear combination\n",
        "    \"\"\"\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "def predict(x, w0, w1):\n",
        "    \"\"\"\n",
        "    predict the label of input x by the perceptron\n",
        "    input: x: the input value\n",
        "           w0: the weight of the bias\n",
        "           w1: the weight of the variable\n",
        "    output: predicted label of x 1 or -1\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "def computeDelta(eta, x, ytrue, ypred):\n",
        "    \"\"\"\n",
        "    compute the amount of weight to be updated for a variable, given\n",
        "    the true label, and the predicted lable\n",
        "    input: eta: learning rate\n",
        "           x: the value of the input variable\n",
        "           ytrue: the true lable (1 or -1)\n",
        "           ypred: the predicted lable (1 or -1)\n",
        "    output: the amount to be updated for the variable\n",
        "    \"\"\"\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "def fit(eta, epochs, X, y, w0, w1, verbose=False):\n",
        "    \"\"\"\n",
        "    fit a single variable perceptron by updating the given weights\n",
        "    input: eta: learning rate\n",
        "           epochs: the number of learning iterations\n",
        "           X: a vector of input values\n",
        "           y: a vector of true labels corresponding to the input values\n",
        "           w0: the weigth of bias\n",
        "           w1: the weight of the variable\n",
        "           verbase: boolean value; if True, print out the intermediate values.\n",
        "    output: (w0, w1): the weights after perceptron learning\n",
        "            errors: the number of mis-classifications in each epoch iteration\n",
        "    \"\"\"\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "    return (w0, w1), errors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXBHCPnNEieU"
      },
      "source": [
        "Step 2: The following function `generateXy()` will generate 25 random values that are in [-1, 0.5] with label -1 and  25 random values that are in [1.5, 3] with label 1. Use the function to create a set of training values $X$ and their corresponding labels $y$. **Plot $X$ and $y$ with different colors for different labels. Also plot a line $z=1-x$ along with the points. Name the plot as \"50 Points and an Initial Model\".**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZztCZV-bEwGa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "def generateXy():\n",
        "    \"\"\"\n",
        "    Generate 25 random values that are in [-1, 0.5] with label -1 and\n",
        "    25 random values that are in [1.5, 3] with label 1.\n",
        "    The values are used for training a single variable perceptron.\n",
        "    Input: None\n",
        "    Output: (X, y): 25 values in [-1, 0.5] with label -1\n",
        "                    and 25 values in [1.5, 3] with label 1\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate 25 random points that x < 0.5 and y = -1\n",
        "    np.random.RandomState(1234)\n",
        "\n",
        "    x1 = np.random.uniform(-1, 0.5, size=25)\n",
        "    y1 = np.ones(len(x1)) * -1\n",
        "\n",
        "    # Generate 25 random points that x > 1.5 and y = 1\n",
        "    x2 = np.random.uniform(1.5, 3, size=25)\n",
        "    y2 = np.ones(len(x2))\n",
        "\n",
        "    x12 = np.concatenate((x1, x2))\n",
        "    y12 = np.concatenate((y1, y2))\n",
        "\n",
        "    Xy = list(zip(x12, y12))\n",
        "    random.shuffle(Xy)\n",
        "\n",
        "    return Xy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCgTnzk3F8F5"
      },
      "outputs": [],
      "source": [
        "# GENERATE TRAINING DATA AND LABELS\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ES_lKyKCGNW9"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE TO PLOT THE POINTS LABELED WITH DIFFERENT COLORS FOR DIFFERENT LABELS\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkomcJGTFX6I"
      },
      "source": [
        "Step 3: Intialize the weights $w_0=1$ and $w_1=-1$. Apply the impelemented `fit()` function at Step 1 on $X$ and $y$ above to learn a new model. Use learning rate $\\eta=1$ and $epochs=5$. Assign the final weights to a variable `weights` and the list errors to a variable `errors`."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UiNtOmalSRDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Va7G_3R9SQ1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymIrp9xvIzFw"
      },
      "source": [
        "Step 4: Plot the points represented by $(X, y)$, the initial model, and the final model learned at Step 3."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3CCbO7TUSScf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yEySiVYVSSZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hQMROq4KJgJ"
      },
      "source": [
        "Step 5: Plot the errors vs. epochs."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7JFoNB3dSToG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z3Bhx2JbSTke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30DrO8wkKYTX"
      },
      "source": [
        "Step 6: Classification accuracy is defined as the ratio of correctly predicted instances to the total instances in a dataset. Compute the classification accuracy of the initial model $1-x$ and the final model learned at Step 3 on the training data $X$. **Discuss the results!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKfeVQaXK3t9"
      },
      "outputs": [],
      "source": [
        "# Classification accuracy using the initial model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8CWAWN1KVZV"
      },
      "outputs": [],
      "source": [
        "# Classification accuracy using the final model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1CSQDvwMilc"
      },
      "source": [
        "Step 7: At this step, you will experiment with different learning rates $\\eta$ when training a model. Create a list of $\\eta$ values as `etas = np.arange(0.1, 1.1, 0.1)`. If neccesary, generate training data $X$ and $y$ using `generateXy()`. Fit a perceptraon model on $X$ and $y$ using each $eta$ value in the list. Initialize $w_0=1$ and $w_1=-1$. Set $epochs=5$ for all the trainings.  You should fit 10 models. Save the weights of the models in `weights_list`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5SOkFAKNwqA"
      },
      "outputs": [],
      "source": [
        "# GENERATE TRAINING DATA AND LABELS\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TAI4KkmgSfFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dB1WICIySfB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzUaRlFzOK36"
      },
      "source": [
        "Step 8: Plot the points represented by $(X, y)$ and the 10 models corresponding to 10 different learning rates $\\eta$. Label each model appropriately. **Explain what you find!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbfoVatBN9yS"
      },
      "outputs": [],
      "source": [
        "# plot the points and the models based on different eta\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8juU3ukPJQb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG3H-MPBQEHu"
      },
      "source": [
        "# Question 2: Implement a single variable Adaline Model\n",
        "In this question, you are asked to implement the Adaline learning algorithm for input with a single variable, i.e., learn a linear function $z=w_0+w_1x$ to classify a single value $x$ as $1$ or $-1$.\n",
        "The Adaline learning algorithm can be summarized by the following steps:\n",
        "1. Initialize the weights $w_0$ and $w_1$.\n",
        "2. For each training example $x^{(i)}$,\n",
        " 1. Compute the linear combination: $z^{(i)}=w_0 + w_1{x}^{(i)}$\n",
        " 2. Compute the activation value of $z^{(i)}$:\n",
        " $activation(z^{(i)})=\\phi(z^{(i)})= z^{(i)}$\n",
        " 3. Compute the error: $e^{(i)} = y^{(i)} - activation(z^{(i)})$\n",
        "3. Update the weight $w_0$ as follows:\n",
        "    * $w_0 := w_0 + \\Delta w_0 = w_0 + \\eta \\Sigma_i e^{(i)}$\n",
        "4. Update the weight $w_1$ as follows:\n",
        "    * $w_1 := w_1 + \\Delta w_1 = w_1 + \\eta \\Sigma_i (e^{(i)}x^{(i)})$\n",
        "5. Compute the costs as:\n",
        "    * costs = $\\frac{1}{2}\\Sigma_i (e^{(i)})^2$\n",
        "6. Where, $\\eta$ is a learning rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drTjEKbTQEHv"
      },
      "source": [
        "Step 1: In the following program, we have defined the functions `computeZ(x, w0, w1)`, `predict(x, w0, w1)`, `activation(z)`, and `fit(eta, epochs, X, y, w0, w1, verbose=False)`. You need to complete the program by finishing the function `fit(eta, epochs, X, y, w0, w1, verbose=False)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moeft3i9Ugxn"
      },
      "outputs": [],
      "source": [
        "# IMPLEMENT THE FOLLOWING FUNCTIONS\n",
        "\n",
        "def computeZ(x, w0, w1):\n",
        "    \"\"\"\n",
        "    compute the output z value given an input and the weights\n",
        "    input: x: the value of the input variable\n",
        "           w0: the weight of the bias\n",
        "           w1: the weight of the variable\n",
        "    output: the value of linear combination\n",
        "    \"\"\"\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "def predict(x, w0, w1):\n",
        "    \"\"\"\n",
        "    predict the label of input x by the perceptron\n",
        "    input: x: the input value\n",
        "           w0: the weight of the bias\n",
        "           w1: the weight of the variable\n",
        "    output: predicted label of x 1 or -1\n",
        "    \"\"\"\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def activation(z):\n",
        "    \"\"\"\n",
        "    compute the activation of the given value\n",
        "    input: z: given value\n",
        "    output: activation of the input value\n",
        "    \"\"\"\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def fit(eta, epochs, X, y, w0, w1, verbose=False):\n",
        "    \"\"\"\n",
        "    fit a single variable Adaline model by updating the given weights\n",
        "    input: eta: learning rate\n",
        "           epochs: the number of learning iterations\n",
        "           X: a vector of input values\n",
        "           y: a vector of true labels corresponding to the input values\n",
        "           w0: the weigth of bias\n",
        "           w1: the weight of the variable\n",
        "           verbose: a boolean value; if True, print out the intermediate values\n",
        "    output: (w0, w1): the weights after Adaline learning\n",
        "            costs: the cost in each epoch\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return (w0, w1), costs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bmExMlrQEHv"
      },
      "source": [
        "Step 2: The following function `generateXy()` will generate 25 random values that are in [-1, 0.5] with label -1 and  25 random values that are in [1.5, 3] with label 1. Use the function to create a set of training values $X$ and their corresponding labels $y$. **Plot $X$ and $y$ with different colors for different labels. Also plot a line $z=1-x$ along with the points. Name the plot as \"50 Points and an Initial Model\".**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18b7xYtmQEHv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "def generateXy():\n",
        "    \"\"\"\n",
        "    Generate 25 random values that are in [-1, 0.5] with label -1 and\n",
        "    25 random values that are in [1.5, 3] with label 1.\n",
        "    The values are used for training a single variable Adaline model.\n",
        "    Input: None\n",
        "    Output: (X, y): 25 values in [-1, 0.5] with label -1\n",
        "                    and 25 values in [1.5, 3] with label 1\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate 25 random points that x < 0.5 and y = -1\n",
        "    np.random.RandomState(1234)\n",
        "\n",
        "    x1 = np.random.uniform(-1, 0.5, size=25)\n",
        "    y1 = np.ones(len(x1)) * -1\n",
        "\n",
        "    # Generate 25 random points that x > 1.5 and y = 1\n",
        "    x2 = np.random.uniform(1.5, 3, size=25)\n",
        "    y2 = np.ones(len(x2))\n",
        "\n",
        "    x12 = np.concatenate((x1, x2))\n",
        "    y12 = np.concatenate((y1, y2))\n",
        "\n",
        "    Xy = list(zip(x12, y12))\n",
        "    random.shuffle(Xy)\n",
        "\n",
        "    return Xy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUtFh_KXQEHv"
      },
      "outputs": [],
      "source": [
        "# GENERATE TRAINING DATA AND LABELS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vp2fZczYQEHv"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE TO PLOT THE POINTS LABELED WITH DIFFERENT COLORS FOR DIFFERENT LABELS\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyICEzCZQEHv"
      },
      "source": [
        "Step 3: Intialize the weights $w_0=1$ and $w_1=-1$. Apply the impelemented Adaline learning function `fit()` at Step 1 on $X$ and $y$ above to learn a model. Use $epochs=30$. Use a learning rate that makes the algorithm converge, for example, 0.001. Assign the final weights to a variable `weights` and the list errors to a variable `costs`."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VjcewoC9SvUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v0mujHlmSvQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxOe7h7yQEHw"
      },
      "source": [
        "Step 4: Plot the points represented by $(X, y)$, the initial model, and the final model learned at Step 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSMQBkgPQEHw"
      },
      "outputs": [],
      "source": [
        "# Plot the points and the final model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiyIB5sZQEHw"
      },
      "source": [
        "Step 5: Plot the costs vs. epochs. **Discuss the results!**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GtwIjkNbS0Th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WP7XrdiwS0Ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jlNeRy_QEH7"
      },
      "source": [
        "Step 6: Classification accuracy is defined as the ratio of correctly predicted instances to the total instances in a dataset. Compute the classification accuracy of the initial model $1-x$ and the final model learned at Step 3 on the training data $X$. **Discuss the results!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvnoyfuXQEH7"
      },
      "outputs": [],
      "source": [
        "# Classification accuracy using the initial model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xrqesCjQEH7"
      },
      "outputs": [],
      "source": [
        "# Classification accuracy using the final model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27drAv9YQEH7"
      },
      "source": [
        "Step 7: At this step, you will experiment with different learning rates $\\eta$ when training a model. Create a list of $\\eta$ values as `etas = [0.0001, 0.001, 0.005, 0.01]` or different list. If neccesary, generate training data $X$ and $y$ using `generateXy()`. Fit a perceptraon model on $X$ and $y$ using each $eta$ value in the list. Initialize $w_0=1$ and $w_1=-1$. Set $epochs=30\\sim 50$ for all the trainings.  You should fit multiple models. Save the weights of the lines in `weights_list`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRS0f10CQEH7"
      },
      "outputs": [],
      "source": [
        "# GENERATE TRAINING DATA AND LABELS\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nVODitCfS7Ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8NTxlW9LS7Jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVNiSCumQEH7"
      },
      "source": [
        "Step 8: Plot the points represented by $(X, y)$ and the decision lines corresponding to different learning rates $\\eta$. Label each line appropriately. **Explain what you find!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRDUMITbQEH7"
      },
      "outputs": [],
      "source": [
        "# plot the points and the models based on different eta\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QypfrRpQEH7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}